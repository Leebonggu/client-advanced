# 브라우저단 최적화

## Caching(HTTP caching)

### 캐시

주어진 리소스의 복사본을 들고 있다가 요청시에 그것을 제공. 웹 캐시가 자신의 저장소 내에
요청된 리소스를 가지고 있다면, 요청을 가로채 원래의 서버로부터 리소스를 다시 다운로드하는 대신
리소스의 복사본을 반환한다

### 웹 캐시의 종류

https://developer.mozilla.org/ko/docs/Web/HTTP/Caching

- private browser cache : 단일 사용자가 전용으로 사용. 브라우저단 캐싱
- shared proxy cache : 한 명 이상의 사용자에 의해 재사용되는 응답을 저장하는 캐시. 캐시 서버, 인메모리 캐시

### 정적 컨텐츠 캐싱

이때 클라이언트에 가까운 것은 프라이빗 캐시 - 브라우저 캐싱  
이미 한번 다운로드 받은 정적 자원들을 컴퓨터의 메모리, 디스크, 프록시 서버, CDN 등등에서 캐싱  
https://medium.com/@codebyamir/a-web-developers-guide-to-browser-caching-cc41f3b73e7c

- 유저가 사이트에 최초 방문 : 캐시된 것이 없으므로 서버에서부터 가져옴. network 하단의 transferred된 바이트
  량 보면 얼마나 많은 데이터가 왔다갔다했는지 알 수 있음(size 표시)
- 이전에 방문한 적이 있다면(캐시에 자원들이 있다면) : 브라우저가 서버에 요청은 보내지만(index.html), 정적 자원들을 서버가 아니라
컴퓨터 내부의 캐시에서 가져온다 (from memory cache, disk cache)
- 어디에서 캐시를 하든 캐시 헤더를 활용하는 느낌

### 갱신

- 리소스에 대한 만료 시간 설정, 만료 시간 이전에는 리소스가 유효함 이후에는 stale
- 캐시가 유효하면 그냥 캐시에있는거 가져다 쓴다
- 캐시가 stale 상태라면(만료시간이 끝났다면) if-None-Match와 함께 요청을 전달하고(Etag 기반하여 갱신 여부를 확인하는 듯)
  서버에서 아직 리소스가 유효한 경우 리소스 본문을 전송하지 않고 304 응답을 돌려보내서 대역폭 절약
    - 이러면 캐시의 만료시간은...? => 갱신되는듯
- max-age 프로퍼티가 헤더에 설정된 경우 이걸 가지고 유효수명을 계산하고, 없으면 Expires를 찾는다
  - Expires는 좀 오래된 헤더인데, 만료가 될 Date 정보를 가지고 있다
- HTML 메타 태그에서도 cache-control 정보를 넣어줄 수 있다. 근데 모든 브라우저가 이를 알아먹을 수 있는건 아니라서 별로 추천은 안댐
- 파일 이름이 바뀌는 경우 해당되는 캐시가 유효하지 않음 => 웹팩 번들 빌드에서 해쉬값을 계속 바꿔서 빌드하는 이유
- 갱신법
  - 퍼지 : 저장소를 완전히 지우는 방식
  - 인밸리데이션 : 조건부 요청을 통해 캐시된 리소스들 중 변경이 있었던 리소스만 새로 갱신
- 캐시키 : 클라이언트가 요청하는 URL. 캐시 서버가 원본의 복사본을 저장하고 바르게 조회하기 위해 사용하는 키값

### 제어 - 캐시 헤더

브라우저는 HTTP 리스폰스의 cache header을 평가하여 캐시를 어떻게 할지 결정한다  
어 근데 s3의 정적 자원같은거는 GET으로 내려받을때 cache header을 어떻게 설정하지? => 먼가 방법이 있겠지 싶음..

- **ETag** : Entity Tag, 원본 서버가 리소스를 식별하기 위해 부여하는 고유 번호. 파일의 해시값. 서버가 응답에 ETag를
  넣어줄 수 있는데, 브라우저는 이 식별자를 가지고 캐시가 stale되었는지 판단한다. (같은 응답에 대해 다른 ETag가 오면?? - invalidation하는? 그런 느낌인가)
  식별자가 같고 자원이 바뀌지 않았을 경우 서버는 304응답(not modified)과 빈 바디를 준다. 브라우저는 304가 오면 캐시에 저장된 자원을 계속 써도 되겠다고 판단한다
    - 콘텐츠 기반의 조건부 요청 : 어떤 요청에 대한 원본 서버의 콘텐츠가 캐시에 저장된 후 변경되었는지 여부를 ETag로 확인하는 방법. 내용이 약간이라도
    수정되면 해시값도 변하기 때문에 이 값을 비교해 컨텐츠의 변경 여부를 잡아낸다
    - 캐시 만료시 If-none-match 헤더에 ETag 값을 복사하여 원본 서버에 전송하면 => 이 콘텐츠와 일치하는 고윳값이 없다면 전체 응답을 다시 주셈
    - 원본 서버는 ETag 값이 같다면 캐시 저장본이 현재 버전과 동일하다 판단해 304응답을 전송하고 캐시를 갱신
- **Cache-Control** : 캐시 동작을 정의하기 위한 헤더
    - public : 모든 캐시 서버에서 캐시될 수 있음(브라우저, CDN 등등 모두)
    - private : 브라우저에서만 캐싱. HTTP 요청에 대한 응답은 요청한 사용자만 캐시할 수 있고 CDN 같은 범용 캐시 서버에서는 캐시할 수 없음
        - cloudFront 설정을 해놓고 cache header을 private으로 가져가면??? => cloudFront에서 캐시 방지가 된다 https://aws.amazon.com/ko/premiumsupport/knowledge-center/prevent-cloudfront-from-caching-files/
    - no-store : 서버가 로컬 저장소(디스크? 메모리?)에 메시지를 저장하지 않도록 지시. 즉 브라우저 캐싱이 이루어지지 않고 서버로 계속 요청을 한다
      다른 캐시 수단이 있어야 사용할 수 있을듯..?
    - no-cache : 캐시된 복사본을 사용자에게 릴리즈하기 전에, 유효성 확인을 위해 원 서버로 요청을 보냄
    - max-age=N : 캐시의 유효기간 설정, s-max-age는 cdn과 같은 공용 캐시 주기 관리
    - must-revalidate : 만료된 리소스는 아예 사용하지 않고 갱신
  

### 동적 컨텐츠 캐싱

- 몇몇 캐시 프록시 서버는 요청 쿠키, 헤더, 쿼리 스트링을 캐시할 수 있다
- Ajax의 경우 : JSON/XML 타입 컨텐츠는 다른 정적 응답 타입과 동일한 방식으로 캐시할 수 있음
  - 캐시 주기를 설정하고 이 시간이 만료된 경우에만 캐시 서버가 원본 서버에서 갱신된 결과를 받아오게 함
  - if-modified-since : 서버가 지정된 시점 이후 수정된 경우에 200, 수정되지 않은 리소스에 대한 요청시 304
  - 서버 캐싱이 어떻게 이루어지는지 살펴봐야할듯.. 인프라에서 어떻게 처리하는지도..
  
결국 인프라단에서 혹은 서버에서 어떤 캐싱 헤더를 끼워넣어서 응답을 보내주는지가 약간 관건 => 인프라랑 섞어서 공부해야할듯

## Critical Rendering Path - 브라우단에서의 렌더링 최적화

중요 렌더링 경로란 브라우저가 HTML, CSS, JS를 화면에 픽셀로 변화하는 일련의 단계를 말하며, 이를 최적화하는 것은 렌더링 성능을 향상시킴

서버의 요청과 응답, 로딩, 스크립팅, 렌더링, 레이아웃, 화면에 픽셀 그리기를 모두 포함하는 과정

### 1. HTML 파싱

- 렌더링 엔진은 네트워크를 통해 받은 HTML 문서를 파싱하고, 콘텐츠 트리 내부에서 태그들을 DOM 노드로 변환한다.
- DOM 변환 : 브라우저가 HTML의 원시 바이트를 디스크(캐싱)나 네트워크에서 읽어와서, 해당 파일에 대해 지정된 인코딩(HTML 헤더에 명시, UTF-8)에 따라 개발 문자로 변환
- 토큰화 : 브라우저가 문자열을 고유 토큰으로 변환하여 태그들의 존재를 파악 => 상태 머신과 같은 알고리즘을 사용해서 열고 닫고 다 파싱
- DOM 생성 : 입력 값은 토큰화되어 만들어지는 일련의 토큰. 계층의 순서대로 파싱이 되기 때문에 토큰을 하나 평가할때마다 계층구조를 인식하여 트리 생성
- **JS 등으로 마크업을 변화시킬때도 파싱 과정을 처음부터 다시 수행함** : 매끄러운 애니메이션을 만드려고 시도하는 경우, 브라우저가 대량의 HTML을 처리해야 한다면 쉽게 병목이 발생할 수 있다.

### 2. CSS 파싱

- CSSOM 파싱 : HTML이 아닌 CSS에 대해서도 비슷한 파싱 프로세스를 반복하여 트리를 만듬. CSSOM도 똑같이 트리 구조로 파싱되는데, 페이지에 있는 객체의 최종 스타일을 계산할 때 브라우저는 해당 노드에 적용 가능한 가장 일반적인 규칙(하위 태그에도 적용이 가능한 넓은 범위의 규칙)으로 시작한 뒤 더 구체적인 규칙을 적용하는 방식으로 계산된 스타일을 재귀적으로 세분화함
- CSS 규칙은 아래로 종속. 분석기는 노드로 변환할때 하위 노드가 스타일을 상속함
- 덜 구체적인 선택지는 더 구체적인 선택자보다 빠르다. 부모 객체와 엮여있는 선택자가 있을 경우 부모에 종속된게 맞는지 DOM을 한 번 더 거슬러 올라가기 때문 => 그치만 신경 쓸 가치까지는 없는 부하

### JS와 CSS => 렌더링 블락 요소

- 기본적으로 CSS는 렌더링 차단 리소스로 취급됨 => CSSOM이 생성될때까지 브라우저는 처리되는 모든 컨텐츠를 렌더링하지 않음 => 브라우저는 DOM과 CSSOM을 모두 사용할 수 있게 될 때까지 렌더링을 차단한다 => 그래서 브라우저에서 CSS가 없고 본문만 있는 화면을 노출하는 것을 방지한다
  - 어찌됐든 DOM트리와 CSSOM의 생성이 끝나야만 렌더 트리 생성으로 넘어간다
  - 동적 미디어 쿼리를 통해 CSS자원을 불러오는 것을 최적화 시킬 수 있다 => 자주 쓰는 일이 많지는 않을듯 싶지만
- 인라인 스크립트를 실행하면 DOM 생성이 차단되고 이로 인해 초기 렌더링도 지연된다
  - body태그의 끝에 있는 스크립트에서 span을 참조하고 있다고 할 경우, span이 생성되기 전으로 script태그의 위치를 옮기면 쿼리셀렉터가 제대로 작동하지 않는다(null)
  - 스크립트를 실행하려는 경우 브라우저가 CSSOM을 다운로드하고 빌드하는 작업을 완료하지 않았다면 브라우저가 CSSOM을 다운로드하고 생성하는 작업을 완료할때까지 스크립트 실행 및 DOM 생성을 지연시킴 => CSSOM이 어쨌든 더 먼저가 된다 JS는 DOM뿐 아니라 CSS 요소에도 접근할 수 있기 때문에 풀세팅이 되어야함
  - 외부 자바스크립트 파일을 HTML에 스크립트 태그로 넣어놓았을 경우 브라우저가 일시 중지하고 네트워크 응답을 기다림 => CRP에 추가적인 지연이 발생

### 3. Render Tree 생성

- 브라우저가 DOM과 CSSOM을 렌더링 트리에 결합한 후, 트리는 페이지에 표시되는 모든 DOM 컨텐츠와 각 노드에 대한 모든 CSSOM 스타일 정보를 캡처
- DOM트리의 루트에서 시작하여 표시되는 노드 각각을 평가 => 표시되지 않는 노드들(메타태그)들 생략, CSS를 통해 숨겨지는(display:none)노드 생략
- 실질적으로 렌더링 되는 노드들은 파싱된 DOM 트리에 다 있지만 실제적인 Render Tree에는 반영이 안 될 수 있다(1:1 대응은 아님)
- 최종 출력은 화면에 표시되는 모든 노드의 내용과 스타일 정보를 모두 포함하는 완전체인 렌더링 트리가 됨. 렌더링 트리가 생성되었으므로 레이아웃 단계로 진행 가능

### 4. Layout(Reflow)

- 그려질 정보는 모두 파악된 셈이니, 직접 그리기 시작하는 레이아웃 단계로 진행이 가능
- 레이아웃 단계 : 만들어진 렌더 트리를 바탕으로 기기 뷰포트 내에 노드의 정확한 위치와 크기를 계산함 => 이때 브라우저는 렌더링 트리의 루트에서 시작하여 렌터링 트리의 노드들을 계속 쫓아감
- 너비나 높이, 수치를 %로 설정했을 경우 상위 노드의 크기를 파악한 후 하위 노드로 넘어감
- 상대적인 측정값들(em, rem, %)은 이 단계에서 절대적인 픽셀값으로 변경됨
- 레이아웃이 완료되면 브라우저가 Paint Setup, Paint 이벤트를 발생시켜 이 과정에서 연산한 값들과 정보를 다음 단계에 저장

### 5.Paint

- 실질적으로 렌터링 트리와 layout 단계에서 수행했던 연산을 바탕으로 렌더링 트리를 화면에 픽셀로 변환하는 작업
- 저렴한 연산이 아님 : 렌더링 트리 생성, 레이아웃 및 paint 작업을 수행하는데 필요한 시간은 문서의 크기, 적용된 스타일 및 실행중인 기기에 따라 달라짐. 문서가 클수록 브라우저가 수행해야 하는 작업도 더 많아지며, 스타일이 복잡할수록 페인팅에 걸리는 시간도 늘어남
- **DOM 또는 CSSOM이 수정된 경우 화면에 다시 렌더링할 필요가 있는 픽셀을 파악하려면 이 프로세스를 다시 반복해야함**

### 참고

- domContentLoaded 이벤트 : DOM트리 빌드까지 걸리는 시간
- 이미지는 렌더링 패스를 블락하지 않는다
- 자바스크립트가 외부에 있을경우 네크워트 비용이 더 들긴 하겠지만 파싱하고 실행하는데는 인라인 스크립트와 크게 다를게 없다
- 돔트리를 만들면서 CSS가 있는 경우 CSS를 가져오고 CSSOM 그리기를 시작
- 자바스크립트가 돔을 modify하는 경우 : DOM트리를 다시 만들고 render tree에 반영함
- CSSOM이 최대한 빨리 만들어져야 JS 실행도 재시간에 되기 때문에 CSS는 헤더에 넣고 JS는 async로 불러오거나(parsing blocking을 하지 않게) body의 끝에 넣는다 => 아예 CSS를 외부에서 가져오지 않는 것도 방법(인라인으로 처리하기)
- 인라인 CSS를 쓰면 캐싱은 안된다(당연하지만)
- DOM 트리 상위 노드의 스타일을 변경하면 하위 노드에 모두 영향을 미친다

### 화면 요소 최적화

최초 렌더링 이후 JS로 DOM이나 CSS를 수정하면 : 파싱을 다시 하여 렌더링 트리를 다시 그리고 layout과 painting을 다시 수행하게 된다 => 다시 발생하는 layout을 reflow, paint를 repaint라고 함

레이아웃은 DOM 요소들이 화면에 어느 위치에 어떤 크기로 배치될지를 결정하게 되는 계산 과정인데, 자바스크립트 코드를 통해 DOM을 변경하거나 스타일을 변경할 경우, 변경된 스타일을 반영하고 다시 레이아웃을 해야만 화면에 렌더링이 가능하다. 레이아웃은 글자의 크기를 일일히 계산하고 요소간 관계를 모두 파악해야 하는 과정이라서 시간이 오래 걸린다

#### 강제 동기 레이아웃

- DOM 속성을 변경하면 화면 업데이트를 위해 레이아웃이 일어날 수 있다. 원래 레이아웃은 비동기적으로 일어나지만 특정 상황에서 동기적으로 레이아웃이 발생할 수 있다.
- 특정 속성을 읽을때 최신 값을 계산하기 위해 레이아웃이 동기적으로 발생하며 이를 강제 동기 레이아웃이라고 함. => 얘는 자바스크립트의 실행 시간을 늘어나게 함으로 신경써야 할 필요가 있다
- 스타일을 변경한 직후에 offsetHeight, offsetTop과 같은 속성으로 값을 읽으면 동기 레이아웃이 수행된다
#### reflow, repaint를 발생시키는 CSS Modification 줄이기

- Transform : transform은 GPU가속으로 처리하기 때문에 reflow와 repaint를 모두 발생시키지 않는다. 뭔가 옮기거나 늘리거나 줄이거나 할때 가능하면 transform을 사용하는게 좋다
- Opacity : opacity도 GPU 가속을 이용하기 때문에 visibility나 display보다는 opacity를 사용하는게 더 좋다
- visibility : invisible은 레이아웃 공간을 차지하기 때문에 reflow의 대상이 되지만, display:none은 아예 렌더트리를 만들대부터 제외되기 때문에 후자가 더 좋다
- position absolute : 주변 영역에 영향을 주지 않도록 하는게 좋은데, position을 absolute나 fixed로 설정하면 주변 레이아웃에 영향을 주지 않는다
- 레이아웃에 관련된 변화들은 대부분 reflow를 발생시키고, 겉모습을 바구는 것들은 대부분 repaint를 발생시킨다. reflow가 일어나면 repaint가 반드시 일어난다

#### 애니메이션 최적화

한 프레임 처리가 16ms 내로 완료되어야 렌더링 시 끊기는 현상 없이 자연스러운 렌더링을 만들어낼 수 있다. 자바스크립트 실행 시간은 10ms이내에 수행되어야 레이아웃, 페인트 등의 과정을 포함했을 때 16ms 이내에 프레임이 완료된다. 

- 애니메이션 구현시 자바스크립트 API보다는 CSS 사용이 권장된다
- requestAnimationFrame : 브라우저의 프레임 속도에 맞추어 애니메이션 실행이 가능하도록 해준다. 프레임을 시작할때 호출되기 때문에 일정한 간격으로 애니메이션을 수행할 수 있는 장점이 있음

## Gzip 압축 서빙

- Audit의 Enable text compression - 프로덕션 환경에서만 나옴
- 정적 자원들의 크기를 줄이는 방법 중 하나
- 헤더에 Content-Encoding: gzip => gzip방식으로 압축이 되어있다는 뜻
- 번들 파일을 서빙해주는 서버에서 관리를 시켜줘야함(S3?)
- Gzip : 파일 압축에 쓰이는 응용 소프트웨어. GNU Zip의 준말이며, 유닉스의 압축 프로그램. 오픈소스. 현재 대부분의 브라우저는 Gzip 압축을 지원하고 있음. 브라우저가 Gzip 압축을 지원하게 되면 브라우저는 서버에게 Accept-Encoding이라는 헤더를 통해 지집을 지원한다고 서버에 알려줄 수 있음. 웹서버는 이 요청을 받고 Gzip을 지원할 응답헤더에 Content-Encoding이라는 헤더를 넣어 보내주게 됨 => 그 자원에 대해서 압축을 푸려고 함
- 압축을 푸는 시간도 있기 때문에 모든 파일을 압축해서 서빙할 필요는 없음
  - 파일 크기가 2kb 이상이면 압축을 하는게 좋은데 아니면 가성비 따져봐야함 => 압축을 해서 얻는 효과보다 압축을 푸는 리소스가 더 크다
- cloudfront단에서 compress 설정을 만질 수 있는듯함 나중에 좀 더 정리..